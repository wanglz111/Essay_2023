{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "singleCNN_Offensevalturk.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvOhQBLWPTC0",
        "outputId": "7a5bb62b-e5dd-4df2-a903-d47f5bd501ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "     \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip install -q keras\n",
        "import keras\n",
        "from os import path\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "print(accelerator)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import csv\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6HarFFqRCv_"
      },
      "source": [
        "## Data Reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU-IAuVzyIeI"
      },
      "source": [
        "# \"\"\"\n",
        "# VALID MODE Wƒ∞TH DOWNSAMPLING\n",
        "# \"\"\"\n",
        "\n",
        "# train=pd.read_csv('/content/drive/My Drive/TURKISH-DATA/TRAIN-TURK-ENCODED')\n",
        "# test=pd.read_csv('/content/drive/My Drive/TURKISH-DATA/TEST-TURK-ENCODED')\n",
        "\n",
        "# X_train_FULL=train[['id','tweet_initial_nontoken','tweet','tweet_initial','subtask_a']]\n",
        "# Y_TRAIN_ENCODED_FULL=train['subtask_a']\n",
        "# X_test_FULL=test[['id','tweet_initial_nontoken','tweet','tweet_initial','subtask_a']]\n",
        "# Y_TEST_ENCODED_FULL=test['subtask_a']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CCKqQSlQ3ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef35788-b019-4aa2-a6ed-a424eb273a0a"
      },
      "source": [
        "# ÂØºÂÖ•ËÆ≠ÁªÉÈõÜÊï∞ÊçÆ ÂúüËÄ≥ÂÖ∂ËØ≠\n",
        "olid_training=pd.read_csv(\"/content/drive/MyDrive/TURKISH-DATA/offenseval-tr-training-v1.tsv\",sep=\"\\t\")\n",
        "X_train_FULL=olid_training[[\"id\",\"tweet\",\"subtask_a\"]] \n",
        "Y_train_FULL=olid_training[\"subtask_a\"]\n",
        "# ÂØºÂÖ•ÊµãËØïÊï∞ÊçÆÂèäÁªìÊûú\n",
        "X_test_FULL=pd.read_csv('/content/drive/MyDrive/TURKISH-DATA/offenseval-tr-testset-v1.tsv',sep='\\t',encoding='utf8',quoting=csv.QUOTE_NONE)\n",
        "Y_TEST=pd.read_csv('/content/drive/MyDrive/TURKISH-DATA/offenseval-tr-labela-v1.tsv',sep=',',encoding='utf8',quoting=csv.QUOTE_NONE,header=None)\n",
        "Y_TRAIN_ENCODED_FULL=[1 if i ==  'OFF' else 0 for i in Y_train_FULL]\n",
        "Y_TEST_ENCODED_FULL = [1 if i ==  'OFF' else 0 for i in Y_TEST[1]]\n",
        "\n",
        "print(\"---ÂØºÂÖ•Êï∞ÊçÆÊàêÂäü---\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ÂØºÂÖ•Êï∞ÊçÆÊàêÂäü---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÂØºÂÖ•ËÆ≠ÁªÉÈõÜÊï∞ÊçÆ Ëã±ËØ≠\n",
        "olid_training=pd.read_csv(\"/content/drive/MyDrive/OLIDv1.0/olid-training-v1.0.tsv\",sep=\"\\t\")\n",
        "X_train_FULL=olid_training[[\"id\",\"tweet\",\"subtask_a\"]] \n",
        "Y_train_FULL=olid_training[\"subtask_a\"]\n",
        "# ÂØºÂÖ•ÊµãËØïÊï∞ÊçÆÂèäÁªìÊûú\n",
        "X_test_FULL=pd.read_csv('/content/drive/MyDrive/OLIDv1.0/testset-levela.tsv',sep='\\t',encoding='utf8',quoting=csv.QUOTE_NONE)\n",
        "Y_TEST=pd.read_csv('/content/drive/MyDrive/OLIDv1.0/labels-levela.csv',sep=',',encoding='utf8',quoting=csv.QUOTE_NONE,header=None)\n",
        "Y_TRAIN_ENCODED_FULL=[1 if i ==  'OFF' else 0 for i in Y_train_FULL]\n",
        "Y_TEST_ENCODED_FULL = [1 if i ==  'OFF' else 0 for i in Y_TEST[1]]\n",
        "\n",
        "print(\"---ÂØºÂÖ•Êï∞ÊçÆÊàêÂäü---\")\n"
      ],
      "metadata": {
        "id": "rNc7J_QoLG7l",
        "outputId": "eeb3083f-a575-4363-c782-0f9751bb8d14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ÂØºÂÖ•Êï∞ÊçÆÊàêÂäü---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVUr2tSbRFTI"
      },
      "source": [
        "Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4LmRLgfQ-9o"
      },
      "source": [
        "# Êï∞ÊçÆÊ∏ÖÊ¥ó\n",
        "X_train_FULL.tweet = X_train_FULL.tweet.str.lower()\n",
        "\n",
        "filtered_tweets=[]\n",
        "for tweet in X_train_FULL[\"tweet\"]:\n",
        "    tweet_tokens = word_tokenize(tweet) \n",
        "\n",
        "    filtered_sentence = [w for w in tweet_tokens if (( w!='user' and w!='url' and w!=':' and w!='@' and w!=',' and w!= \"'\" and w!='.'and w!='#' and w!='?'))] \n",
        "      \n",
        "    filtered_tweets.append(filtered_sentence)\n",
        "\n",
        "X_train_FULL[\"tweet_initial\"]=filtered_tweets\n",
        "\n",
        "\n",
        "X_test_FULL.tweet = X_test_FULL.tweet.str.lower()\n",
        "\n",
        "filtered_tweets=[]\n",
        "for tweet in X_test_FULL[\"tweet\"]:\n",
        "    tweet_tokens = word_tokenize(tweet) \n",
        "\n",
        "    filtered_sentence = [w for w in tweet_tokens if (( w!='user' and w!='url' and w!=':' and w!='@' and w!=',' and w!= \"'\" and w!='.'and w!='#' and w!='?'))] \n",
        "      \n",
        "    filtered_tweets.append(filtered_sentence)\n",
        "\n",
        "X_test_FULL[\"tweet_initial\"] = filtered_tweets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#FOR TEST\n",
        "\n",
        "z=[]\n",
        "for tweet in X_train_FULL[\"tweet_initial\"]:\n",
        "    d=\" \".join(tweet)\n",
        "    z.append(d)\n",
        "X_train_FULL[\"tweet_initial_nontoken\"]=z\n",
        "\n",
        "\n",
        "\n",
        "#FOR TEST\n",
        "\n",
        "z=[]\n",
        "for tweet in X_test_FULL[\"tweet_initial\"]:\n",
        "    d=\" \".join(tweet)\n",
        "    z.append(d)\n",
        "X_test_FULL[\"tweet_initial_nontoken\"]=z\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_FULL"
      ],
      "metadata": {
        "id": "X-x4msE1NcJX",
        "outputId": "c35f906a-f474-4fc0-f8fd-8394c822a899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              tweet  \\\n",
              "0    15923  #whoisq #wherestheserver #dumpnike #declasfisa...   \n",
              "1    27014  #constitutionday is revered by conservatives, ...   \n",
              "2    30530  #foxnews #nra #maga #potus #trump #2ndamendmen...   \n",
              "3    13876  #watching #boomer getting the news that she is...   \n",
              "4    60133  #nopasaran: unity demo to oppose the far-right...   \n",
              "..     ...                                                ...   \n",
              "855  73439  #despicabledems lie again about rifles. dem di...   \n",
              "856  25657  #meetthespeakers üôå @user will present in our e...   \n",
              "857  67018  3 people just unfollowed me for talking about ...   \n",
              "858  50665  #wednesdaywisdom antifa calls the right fascis...   \n",
              "859  24583      #kavanaugh typical #liberals , #democrats url   \n",
              "\n",
              "                                         tweet_initial  \\\n",
              "0    [whoisq, wherestheserver, dumpnike, declasfisa...   \n",
              "1    [constitutionday, is, revered, by, conservativ...   \n",
              "2    [foxnews, nra, maga, potus, trump, 2ndamendmen...   \n",
              "3    [watching, boomer, getting, the, news, that, s...   \n",
              "4    [nopasaran, unity, demo, to, oppose, the, far-...   \n",
              "..                                                 ...   \n",
              "855  [despicabledems, lie, again, about, rifles, de...   \n",
              "856  [meetthespeakers, üôå, will, present, in, our, e...   \n",
              "857  [3, people, just, unfollowed, me, for, talking...   \n",
              "858  [wednesdaywisdom, antifa, calls, the, right, f...   \n",
              "859          [kavanaugh, typical, liberals, democrats]   \n",
              "\n",
              "                                tweet_initial_nontoken  \n",
              "0    whoisq wherestheserver dumpnike declasfisa dem...  \n",
              "1    constitutionday is revered by conservatives ha...  \n",
              "2    foxnews nra maga potus trump 2ndamendment rnc ...  \n",
              "3    watching boomer getting the news that she is s...  \n",
              "4    nopasaran unity demo to oppose the far-right i...  \n",
              "..                                                 ...  \n",
              "855  despicabledems lie again about rifles dem dist...  \n",
              "856  meetthespeakers üôå will present in our event oi...  \n",
              "857  3 people just unfollowed me for talking about ...  \n",
              "858  wednesdaywisdom antifa calls the right fascist...  \n",
              "859               kavanaugh typical liberals democrats  \n",
              "\n",
              "[860 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e2fd088-9e3f-4895-9bc5-e5fc94cd4d1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_initial</th>\n",
              "      <th>tweet_initial_nontoken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15923</td>\n",
              "      <td>#whoisq #wherestheserver #dumpnike #declasfisa...</td>\n",
              "      <td>[whoisq, wherestheserver, dumpnike, declasfisa...</td>\n",
              "      <td>whoisq wherestheserver dumpnike declasfisa dem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27014</td>\n",
              "      <td>#constitutionday is revered by conservatives, ...</td>\n",
              "      <td>[constitutionday, is, revered, by, conservativ...</td>\n",
              "      <td>constitutionday is revered by conservatives ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30530</td>\n",
              "      <td>#foxnews #nra #maga #potus #trump #2ndamendmen...</td>\n",
              "      <td>[foxnews, nra, maga, potus, trump, 2ndamendmen...</td>\n",
              "      <td>foxnews nra maga potus trump 2ndamendment rnc ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13876</td>\n",
              "      <td>#watching #boomer getting the news that she is...</td>\n",
              "      <td>[watching, boomer, getting, the, news, that, s...</td>\n",
              "      <td>watching boomer getting the news that she is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60133</td>\n",
              "      <td>#nopasaran: unity demo to oppose the far-right...</td>\n",
              "      <td>[nopasaran, unity, demo, to, oppose, the, far-...</td>\n",
              "      <td>nopasaran unity demo to oppose the far-right i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>73439</td>\n",
              "      <td>#despicabledems lie again about rifles. dem di...</td>\n",
              "      <td>[despicabledems, lie, again, about, rifles, de...</td>\n",
              "      <td>despicabledems lie again about rifles dem dist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>25657</td>\n",
              "      <td>#meetthespeakers üôå @user will present in our e...</td>\n",
              "      <td>[meetthespeakers, üôå, will, present, in, our, e...</td>\n",
              "      <td>meetthespeakers üôå will present in our event oi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>67018</td>\n",
              "      <td>3 people just unfollowed me for talking about ...</td>\n",
              "      <td>[3, people, just, unfollowed, me, for, talking...</td>\n",
              "      <td>3 people just unfollowed me for talking about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>50665</td>\n",
              "      <td>#wednesdaywisdom antifa calls the right fascis...</td>\n",
              "      <td>[wednesdaywisdom, antifa, calls, the, right, f...</td>\n",
              "      <td>wednesdaywisdom antifa calls the right fascist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>24583</td>\n",
              "      <td>#kavanaugh typical #liberals , #democrats url</td>\n",
              "      <td>[kavanaugh, typical, liberals, democrats]</td>\n",
              "      <td>kavanaugh typical liberals democrats</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>860 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e2fd088-9e3f-4895-9bc5-e5fc94cd4d1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e2fd088-9e3f-4895-9bc5-e5fc94cd4d1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e2fd088-9e3f-4895-9bc5-e5fc94cd4d1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÊµãËØïÊ∏ÖÊ¥óÂêéÁöÑÊï∞ÊçÆ\n",
        "X_train_FULL = np.array(X_train_FULL)\n",
        "X_test_FULL = np.array(X_test_FULL)\n",
        "Y_TRAIN_ENCODED_FULL = np.array(Y_TRAIN_ENCODED_FULL)\n",
        "Y_TEST_ENCODED_FULL = np.array(Y_TEST_ENCODED_FULL)\n"
      ],
      "metadata": {
        "id": "FpmbibSMHF5m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XmFNtEjRWJr"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "def recall_m(true_Y, pred_Y):\n",
        "        TP = K.sum(K.round(K.clip(true_Y * pred_Y, 0, 1)))\n",
        "        possible_pos = K.sum(K.round(K.clip(true_Y, 0, 1)))\n",
        "        rec = TP / (possible_pos + K.epsilon())\n",
        "        return rec\n",
        "\n",
        "def precision_m(true_Y, pred_Y):\n",
        "        true_positives = K.sum(K.round(K.clip(true_Y * pred_Y, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(pred_Y, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "def f1_m(true_Y, pred_Y):\n",
        "    pres = precision_m(true_Y, pred_Y)\n",
        "    rec = recall_m(true_Y, pred_Y)\n",
        "    return 2*((pres*rec)/(pres+rec+K.epsilon()))\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84q_PQ7zRrso"
      },
      "source": [
        "## Tweeter Word2vec / Custom Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IukK4-MQRv8m"
      },
      "source": [
        "fname= \"/content/drive/My Drive/Twitter/Word2Vec/w2v_model_word.vec\"\n",
        "\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(fname)  # you can load this saved keyedvectors model later\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBfCpzlOhbX8"
      },
      "source": [
        "# Tweeter FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKeL2xpXheOI"
      },
      "source": [
        "import gensim\n",
        "from gensim.models import FastText\n",
        "\n",
        "word_vectors = gensim.models.FastText.load_fasttext_format('/content/drive/My Drive/Twitter/FastText/fastText_25022020.bin',encoding='utf-8') # use that if you want to use fasttedxt \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0MPbhyWI9KO"
      },
      "source": [
        "# Public FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TP47sHiJBFl"
      },
      "source": [
        "word_vectors = gensim.models.FastText.load_fasttext_format('/content/drive/My Drive/OFFENSEVAL20-DATA/haber-P1_S0_L0.bin',encoding='utf-8') # use that if you want to use fasttedxt \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBg1YjQoys4O"
      },
      "source": [
        "# Public word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBnqjhEIyxEB"
      },
      "source": [
        "\n",
        "fname= \"/content/drive/MyDrive/GoogleNews-vectors-negative300.bin.gz\"\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(fname, binary = True)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4BMGRxqR6Bx"
      },
      "source": [
        "## Tokenizing / creating vocabulary and wordindex using keras functinalities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJcARFL7R_Au"
      },
      "source": [
        "\"\"\"\n",
        "We will use word indexes as look-up table during embedding layer.\n",
        "\"\"\"\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=98790)  #the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\n",
        "tokenizer.fit_on_texts(X_train_FULL[\"tweet_initial_nontoken\"])\n",
        "X_train_initial = tokenizer.texts_to_sequences(X_train_FULL[\"tweet_initial_nontoken\"])\n",
        "X_test_initial = tokenizer.texts_to_sequences(X_test_FULL[\"tweet_initial_nontoken\"])\n",
        "vocab_size_initial = len(tokenizer.word_index) + 1 \n",
        "wordIndex_initial=tokenizer.word_index # it is  index\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "max_len = 50\n",
        "\n",
        "\"\"\"\n",
        "Padding\n",
        "\n",
        "\"\"\"\n",
        "X_train_initial = pad_sequences(X_train_initial, padding='post', maxlen=max_len)\n",
        "X_test_initial = pad_sequences(X_test_initial, padding='post', maxlen=max_len)\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncWG_7yISOV9"
      },
      "source": [
        "def createEmbeddingLayer(wordIndex,not_static):\n",
        "  a=[]\n",
        "  embedding_dim=300\n",
        "  vocabulary_size=len(wordIndex)+1\n",
        "  embedding_matrix = np.zeros((vocabulary_size, embedding_dim))\n",
        "  missed=0\n",
        "  for word, i in wordIndex.items():\n",
        "    \n",
        "          \n",
        "      try:\n",
        "          embedding_vector = word_vectors[word] # or fast text\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "            \n",
        "\n",
        "      except KeyError: # If word is not found in the word2vec vocabulary , assign random weights\n",
        "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),embedding_dim)\n",
        "        missed+=1\n",
        "        a.append(word)\n",
        "\n",
        "  print('missed_words :' , missed)\n",
        "\n",
        "  custom_embedding_layer = Embedding(vocabulary_size,\n",
        "                                embedding_dim,\n",
        "                                weights=[embedding_matrix],\n",
        "                                trainable=not_static )# Controls the updating weights )\n",
        "  return custom_embedding_layer\n",
        "\n",
        "  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNCtNSjWSdBD"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import pickle\n",
        "from keras.layers import GRU\n",
        "\n",
        "def cnn(vocab_size,X_train,X_test,y_train,y_test,wordIndex,trainable):\n",
        "  early_stopping = [EarlyStopping(monitor='val_loss',\n",
        "                        min_delta=0,restore_best_weights=True,\n",
        "                        patience=5,\n",
        "                        verbose=1, mode='auto')]\n",
        "  model = Sequential()\n",
        "  model.add(createEmbeddingLayer(wordIndex,trainable))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(GRU(32))\n",
        "  #model.add(Conv1D(128, 1, activation='relu'))\n",
        "  # model.add(Conv1D(128, 3, activation='relu'))\n",
        "  # model.add(layers.GlobalMaxPooling1D())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  #model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "  # model.add(layers.Dense(100, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False), metrics=['acc',f1_m,precision_m, recall_m])\n",
        "  ## Fit the model\n",
        "  model.fit(X_train, y_train, validation_split=0.1, epochs=20,callbacks=early_stopping,batch_size=32)\n",
        "  loss, accuracy, f1_score, precision, recall = model.evaluate(X_train, y_train, verbose=1)\n",
        "  print(\"cnn Training Loss: {:.4f}\".format(loss))\n",
        "  print(\"cnn Training Accuracy: {:.4f}\".format(accuracy))\n",
        "  print(\"cnn Training f1 score: {:.4f}\".format(f1_score))\n",
        "  print(\"cnn Training Precision: {:.4f}\".format(precision))\n",
        "  print(\"cnn Training Recall: {:.4f}\".format(recall))\n",
        "\n",
        "  loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=1)\n",
        "  print(\"cnn Test Loss: {:.4f}\".format(loss))\n",
        "  print(\"cnn Test Accuracy: {:.4f}\".format(accuracy))\n",
        "  print(\"cnn Test f1 score: {:.4f}\".format(f1_score))\n",
        "  print(\"cnn Test Precision: {:.4f}\".format(precision))\n",
        "  print(\"cnn Test Recall: {:.4f}\".format(recall))\n",
        "\n",
        "  probs = model.predict(X_test, verbose=1)\n",
        "  predicted_classes = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "  #filename = 'finalized_model_lstm.sav'\n",
        "  #pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "  print(classification_report(y_test, predicted_classes ,digits=3 ))\n",
        "\n",
        "\n",
        "  print(\"cnn  ends..\")\n",
        "  return (predicted_classes,probs)\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_FULL = np.array(X_train_FULL)\n",
        "X_test_FULL = np.array(X_test_FULL)\n",
        "Y_TRAIN_ENCODED_FULL = np.array(Y_TRAIN_ENCODED_FULL)\n",
        "Y_TEST_ENCODED_FULL = np.array(Y_TEST_ENCODED_FULL)"
      ],
      "metadata": {
        "id": "GI_jlKaNO09Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KYhLt04DSNU",
        "outputId": "697e419a-38ac-497c-e227-0e3b7cb58104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "Without Undersampled test results are in below \"public w2v\"\n",
        "\"\"\"\n",
        "prediction_cnnlstm,probs_cnnlstm=cnn(vocab_size_initial,X_train_initial,X_test_initial,Y_TRAIN_ENCODED_FULL,Y_TEST_ENCODED_FULL,wordIndex_initial,False)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missed_words : 5319\n",
            "Epoch 1/20\n",
            "373/373 [==============================] - 16s 35ms/step - loss: 0.6384 - acc: 0.6663 - f1_m: 0.0190 - precision_m: 0.0943 - recall_m: 0.0108 - val_loss: 0.6398 - val_acc: 0.6669 - val_f1_m: 0.0053 - val_precision_m: 0.0238 - val_recall_m: 0.0030\n",
            "Epoch 2/20\n",
            "373/373 [==============================] - 13s 34ms/step - loss: 0.6320 - acc: 0.6716 - f1_m: 0.0538 - precision_m: 0.2248 - recall_m: 0.0317 - val_loss: 0.6338 - val_acc: 0.6654 - val_f1_m: 0.0199 - val_precision_m: 0.1190 - val_recall_m: 0.0109\n",
            "Epoch 3/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.5566 - acc: 0.7327 - f1_m: 0.4752 - precision_m: 0.5978 - recall_m: 0.4574 - val_loss: 0.4997 - val_acc: 0.7681 - val_f1_m: 0.6440 - val_precision_m: 0.6342 - val_recall_m: 0.6707\n",
            "Epoch 4/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.4857 - acc: 0.7796 - f1_m: 0.6251 - precision_m: 0.7034 - recall_m: 0.5937 - val_loss: 0.4853 - val_acc: 0.7802 - val_f1_m: 0.6359 - val_precision_m: 0.7034 - val_recall_m: 0.5965\n",
            "Epoch 5/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.4642 - acc: 0.7850 - f1_m: 0.6316 - precision_m: 0.7252 - recall_m: 0.5866 - val_loss: 0.4904 - val_acc: 0.7734 - val_f1_m: 0.6614 - val_precision_m: 0.6561 - val_recall_m: 0.6834\n",
            "Epoch 6/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.4467 - acc: 0.7997 - f1_m: 0.6574 - precision_m: 0.7325 - recall_m: 0.6193 - val_loss: 0.4876 - val_acc: 0.7681 - val_f1_m: 0.6611 - val_precision_m: 0.6353 - val_recall_m: 0.7037\n",
            "Epoch 7/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.4395 - acc: 0.8016 - f1_m: 0.6680 - precision_m: 0.7422 - recall_m: 0.6352 - val_loss: 0.4725 - val_acc: 0.7991 - val_f1_m: 0.6597 - val_precision_m: 0.7495 - val_recall_m: 0.6075\n",
            "Epoch 8/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.4292 - acc: 0.8081 - f1_m: 0.6776 - precision_m: 0.7598 - recall_m: 0.6395 - val_loss: 0.4603 - val_acc: 0.7968 - val_f1_m: 0.6556 - val_precision_m: 0.7339 - val_recall_m: 0.6112\n",
            "Epoch 9/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.4194 - acc: 0.8129 - f1_m: 0.6807 - precision_m: 0.7621 - recall_m: 0.6445 - val_loss: 0.4609 - val_acc: 0.7961 - val_f1_m: 0.6363 - val_precision_m: 0.7739 - val_recall_m: 0.5592\n",
            "Epoch 10/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.4072 - acc: 0.8197 - f1_m: 0.6914 - precision_m: 0.7727 - recall_m: 0.6484 - val_loss: 0.4722 - val_acc: 0.7885 - val_f1_m: 0.6638 - val_precision_m: 0.6849 - val_recall_m: 0.6594\n",
            "Epoch 11/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.4006 - acc: 0.8207 - f1_m: 0.6962 - precision_m: 0.7703 - recall_m: 0.6605 - val_loss: 0.4669 - val_acc: 0.7931 - val_f1_m: 0.6589 - val_precision_m: 0.7218 - val_recall_m: 0.6203\n",
            "Epoch 12/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.3930 - acc: 0.8267 - f1_m: 0.7041 - precision_m: 0.7786 - recall_m: 0.6707 - val_loss: 0.4796 - val_acc: 0.7840 - val_f1_m: 0.6414 - val_precision_m: 0.6997 - val_recall_m: 0.6078\n",
            "Epoch 13/20\n",
            "373/373 [==============================] - ETA: 0s - loss: 0.3814 - acc: 0.8358 - f1_m: 0.7274 - precision_m: 0.7878 - recall_m: 0.6998Restoring model weights from the end of the best epoch: 8.\n",
            "373/373 [==============================] - 12s 34ms/step - loss: 0.3814 - acc: 0.8358 - f1_m: 0.7274 - precision_m: 0.7878 - recall_m: 0.6998 - val_loss: 0.4824 - val_acc: 0.7938 - val_f1_m: 0.6421 - val_precision_m: 0.7481 - val_recall_m: 0.5754\n",
            "Epoch 13: early stopping\n",
            "414/414 [==============================] - 4s 9ms/step - loss: 0.4056 - acc: 0.8235 - f1_m: 0.7000 - precision_m: 0.7780 - recall_m: 0.6550\n",
            "cnn Training Loss: 0.4056\n",
            "cnn Training Accuracy: 0.8235\n",
            "cnn Training f1 score: 0.7000\n",
            "cnn Training Precision: 0.7780\n",
            "cnn Training Recall: 0.6550\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.3797 - acc: 0.8384 - f1_m: 0.6482 - precision_m: 0.7839 - recall_m: 0.5764\n",
            "cnn Test Loss: 0.3797\n",
            "cnn Test Accuracy: 0.8384\n",
            "cnn Test f1 score: 0.6482\n",
            "cnn Test Precision: 0.7839\n",
            "cnn Test Recall: 0.5764\n",
            "27/27 [==============================] - 1s 9ms/step\n",
            "27/27 [==============================] - 0s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.855     0.934     0.893       620\n",
            "           1      0.776     0.592     0.671       240\n",
            "\n",
            "    accuracy                          0.838       860\n",
            "   macro avg      0.816     0.763     0.782       860\n",
            "weighted avg      0.833     0.838     0.831       860\n",
            "\n",
            "cnn  ends..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UImw59AaDBRt",
        "outputId": "2585e2e3-4a7d-49f6-d3b6-89a17e37157a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "Without Undersampled valid results are in below \"public w2v\"\n",
        "\"\"\"\n",
        "prediction_cnnlstm,probs_cnnlstm=cnn(vocab_size_initial,X_train_initial,X_test_initial,Y_TRAIN_ENCODED_FULL,Y_TEST_ENCODED_FULL,wordIndex_initial,False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missed_words : 5319\n",
            "Epoch 1/20\n",
            "373/373 [==============================] - 14s 35ms/step - loss: 0.5804 - acc: 0.7078 - f1_m: 0.3549 - precision_m: 0.5373 - recall_m: 0.3069 - val_loss: 0.4925 - val_acc: 0.7734 - val_f1_m: 0.5995 - val_precision_m: 0.7294 - val_recall_m: 0.5324\n",
            "Epoch 2/20\n",
            "373/373 [==============================] - 15s 40ms/step - loss: 0.4757 - acc: 0.7765 - f1_m: 0.6031 - precision_m: 0.7212 - recall_m: 0.5485 - val_loss: 0.4802 - val_acc: 0.7795 - val_f1_m: 0.5817 - val_precision_m: 0.7853 - val_recall_m: 0.4767\n",
            "Epoch 3/20\n",
            "373/373 [==============================] - 12s 32ms/step - loss: 0.4349 - acc: 0.7986 - f1_m: 0.6488 - precision_m: 0.7507 - recall_m: 0.6054 - val_loss: 0.5370 - val_acc: 0.7364 - val_f1_m: 0.6443 - val_precision_m: 0.5694 - val_recall_m: 0.7656\n",
            "Epoch 4/20\n",
            "373/373 [==============================] - 13s 34ms/step - loss: 0.4004 - acc: 0.8166 - f1_m: 0.6870 - precision_m: 0.7730 - recall_m: 0.6512 - val_loss: 0.5000 - val_acc: 0.7795 - val_f1_m: 0.6086 - val_precision_m: 0.6987 - val_recall_m: 0.5602\n",
            "Epoch 5/20\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.3586 - acc: 0.8397 - f1_m: 0.7351 - precision_m: 0.7966 - recall_m: 0.7090 - val_loss: 0.5158 - val_acc: 0.7764 - val_f1_m: 0.6013 - val_precision_m: 0.7098 - val_recall_m: 0.5417\n",
            "Epoch 6/20\n",
            "373/373 [==============================] - 17s 46ms/step - loss: 0.3188 - acc: 0.8586 - f1_m: 0.7739 - precision_m: 0.8166 - recall_m: 0.7590 - val_loss: 0.5731 - val_acc: 0.7734 - val_f1_m: 0.5735 - val_precision_m: 0.7163 - val_recall_m: 0.4935\n",
            "Epoch 7/20\n",
            "372/373 [============================>.] - ETA: 0s - loss: 0.2839 - acc: 0.8810 - f1_m: 0.8049 - precision_m: 0.8444 - recall_m: 0.7944Restoring model weights from the end of the best epoch: 2.\n",
            "373/373 [==============================] - 12s 33ms/step - loss: 0.2841 - acc: 0.8810 - f1_m: 0.8049 - precision_m: 0.8439 - recall_m: 0.7949 - val_loss: 0.5738 - val_acc: 0.7636 - val_f1_m: 0.6483 - val_precision_m: 0.6193 - val_recall_m: 0.6969\n",
            "Epoch 7: early stopping\n",
            "414/414 [==============================] - 5s 12ms/step - loss: 0.4152 - acc: 0.8039 - f1_m: 0.6283 - precision_m: 0.8193 - recall_m: 0.5282\n",
            "cnn Training Loss: 0.4152\n",
            "cnn Training Accuracy: 0.8039\n",
            "cnn Training f1 score: 0.6283\n",
            "cnn Training Precision: 0.8193\n",
            "cnn Training Recall: 0.5282\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4262 - acc: 0.8337 - f1_m: 0.5846 - precision_m: 0.8459 - recall_m: 0.4680\n",
            "cnn Test Loss: 0.4262\n",
            "cnn Test Accuracy: 0.8337\n",
            "cnn Test f1 score: 0.5846\n",
            "cnn Test Precision: 0.8459\n",
            "cnn Test Recall: 0.4680\n",
            "27/27 [==============================] - 0s 10ms/step\n",
            "27/27 [==============================] - 0s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.829     0.969     0.894       620\n",
            "           1      0.859     0.483     0.619       240\n",
            "\n",
            "    accuracy                          0.834       860\n",
            "   macro avg      0.844     0.726     0.756       860\n",
            "weighted avg      0.837     0.834     0.817       860\n",
            "\n",
            "cnn  ends..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUV_hqhYCuy7",
        "outputId": "e4ec3b1d-e268-4eef-ecef-d973e12330da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "\"\"\"\n",
        "With Undersampled test results are in below \"public w2v\"\n",
        "\"\"\"\n",
        "prediction_cnnlstm,probs_cnnlstm=cnn(vocab_size_initial,X_train_initial,X_test_initial,Y_TRAIN_ENCODED_FULL,Y_TEST_ENCODED_FULL,wordIndex_initial,False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "missed_words : 17612\n",
            "Train on 20787 samples, validate on 2310 samples\n",
            "Epoch 1/20\n",
            "20787/20787 [==============================] - 4s 175us/step - loss: 0.4757 - acc: 0.7904 - f1_m: 0.5349 - precision_m: 0.6740 - recall_m: 0.4973 - val_loss: 0.4632 - val_acc: 0.7978 - val_f1_m: 0.5572 - val_precision_m: 0.4667 - val_recall_m: 0.7500\n",
            "Epoch 2/20\n",
            "20787/20787 [==============================] - 3s 151us/step - loss: 0.3802 - acc: 0.8370 - f1_m: 0.6426 - precision_m: 0.7653 - recall_m: 0.5901 - val_loss: 0.3291 - val_acc: 0.8658 - val_f1_m: 0.4966 - val_precision_m: 0.6489 - val_recall_m: 0.4326\n",
            "Epoch 3/20\n",
            "20787/20787 [==============================] - 3s 155us/step - loss: 0.3398 - acc: 0.8512 - f1_m: 0.6753 - precision_m: 0.7887 - recall_m: 0.6327 - val_loss: 0.3310 - val_acc: 0.8654 - val_f1_m: 0.5440 - val_precision_m: 0.6523 - val_recall_m: 0.5109\n",
            "Epoch 4/20\n",
            "20787/20787 [==============================] - 3s 155us/step - loss: 0.3032 - acc: 0.8722 - f1_m: 0.7241 - precision_m: 0.8249 - recall_m: 0.6816 - val_loss: 0.3680 - val_acc: 0.8494 - val_f1_m: 0.5708 - val_precision_m: 0.5683 - val_recall_m: 0.6152\n",
            "Epoch 5/20\n",
            "20787/20787 [==============================] - 3s 159us/step - loss: 0.2583 - acc: 0.8925 - f1_m: 0.7788 - precision_m: 0.8496 - recall_m: 0.7488 - val_loss: 0.3705 - val_acc: 0.8615 - val_f1_m: 0.5256 - val_precision_m: 0.6522 - val_recall_m: 0.4821\n",
            "Epoch 6/20\n",
            "20787/20787 [==============================] - 3s 155us/step - loss: 0.2223 - acc: 0.9089 - f1_m: 0.8139 - precision_m: 0.8725 - recall_m: 0.7890 - val_loss: 0.4386 - val_acc: 0.8247 - val_f1_m: 0.5545 - val_precision_m: 0.5064 - val_recall_m: 0.6648\n",
            "Epoch 7/20\n",
            "20787/20787 [==============================] - 3s 158us/step - loss: 0.1901 - acc: 0.9231 - f1_m: 0.8442 - precision_m: 0.8876 - recall_m: 0.8264 - val_loss: 0.4698 - val_acc: 0.8242 - val_f1_m: 0.5471 - val_precision_m: 0.5081 - val_recall_m: 0.6402\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00007: early stopping\n",
            "23097/23097 [==============================] - 2s 67us/step\n",
            "cnn Training Loss: 0.2977\n",
            "cnn Training Accuracy: 0.8676\n",
            "cnn Training f1 score: 0.6567\n",
            "cnn Training Precision: 0.8949\n",
            "cnn Training Recall: 0.5427\n",
            "3528/3528 [==============================] - 0s 77us/step\n",
            "cnn Test Loss: 0.3560\n",
            "cnn Test Accuracy: 0.8571\n",
            "cnn Test f1 score: 0.5313\n",
            "cnn Test Precision: 0.7609\n",
            "cnn Test Recall: 0.4476\n",
            "3528/3528 [==============================] - 0s 45us/step\n",
            "3528/3528 [==============================] - 0s 37us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.873     0.961     0.915      2812\n",
            "           1      0.744     0.451     0.562       716\n",
            "\n",
            "    accuracy                          0.857      3528\n",
            "   macro avg      0.809     0.706     0.738      3528\n",
            "weighted avg      0.847     0.857     0.843      3528\n",
            "\n",
            "cnn  ends..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp6ImAB45K6Z",
        "outputId": "e8860046-5efd-4c58-a41f-670ee22a3c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "\"\"\"\n",
        "With Undersampled valid results are in below \"public w2v\"\n",
        "\"\"\"\n",
        "prediction_cnnlstm,probs_cnnlstm=cnn(vocab_size_initial,X_train_initial,X_test_initial,Y_TRAIN_ENCODED_FULL,Y_TEST_ENCODED_FULL,wordIndex_initial,False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "missed_words : 13202\n",
            "Train on 15161 samples, validate on 1685 samples\n",
            "Epoch 1/20\n",
            "15161/15161 [==============================] - 3s 178us/step - loss: 0.4985 - acc: 0.7708 - f1_m: 0.5305 - precision_m: 0.6591 - recall_m: 0.5019 - val_loss: 0.4337 - val_acc: 0.8036 - val_f1_m: 0.6457 - val_precision_m: 0.6524 - val_recall_m: 0.6673\n",
            "Epoch 2/20\n",
            "15161/15161 [==============================] - 2s 147us/step - loss: 0.3877 - acc: 0.8298 - f1_m: 0.6584 - precision_m: 0.7722 - recall_m: 0.6127 - val_loss: 0.4279 - val_acc: 0.8160 - val_f1_m: 0.5902 - val_precision_m: 0.7794 - val_recall_m: 0.4945\n",
            "Epoch 3/20\n",
            "15161/15161 [==============================] - 2s 148us/step - loss: 0.3365 - acc: 0.8552 - f1_m: 0.7114 - precision_m: 0.8075 - recall_m: 0.6721 - val_loss: 0.4265 - val_acc: 0.8172 - val_f1_m: 0.6213 - val_precision_m: 0.7596 - val_recall_m: 0.5477\n",
            "Epoch 4/20\n",
            "15161/15161 [==============================] - 2s 154us/step - loss: 0.2905 - acc: 0.8758 - f1_m: 0.7568 - precision_m: 0.8380 - recall_m: 0.7238 - val_loss: 0.4607 - val_acc: 0.7988 - val_f1_m: 0.6471 - val_precision_m: 0.6344 - val_recall_m: 0.6836\n",
            "Epoch 5/20\n",
            "15161/15161 [==============================] - 2s 152us/step - loss: 0.2372 - acc: 0.9014 - f1_m: 0.8094 - precision_m: 0.8664 - recall_m: 0.7841 - val_loss: 0.5307 - val_acc: 0.8095 - val_f1_m: 0.5633 - val_precision_m: 0.7700 - val_recall_m: 0.4616\n",
            "Epoch 6/20\n",
            "15161/15161 [==============================] - 2s 150us/step - loss: 0.2009 - acc: 0.9184 - f1_m: 0.8463 - precision_m: 0.8877 - recall_m: 0.8280 - val_loss: 0.5434 - val_acc: 0.8107 - val_f1_m: 0.5931 - val_precision_m: 0.7453 - val_recall_m: 0.5158\n",
            "Epoch 7/20\n",
            "15161/15161 [==============================] - 2s 149us/step - loss: 0.1759 - acc: 0.9288 - f1_m: 0.8653 - precision_m: 0.8982 - recall_m: 0.8528 - val_loss: 0.5975 - val_acc: 0.8024 - val_f1_m: 0.5918 - val_precision_m: 0.7236 - val_recall_m: 0.5208\n",
            "Epoch 8/20\n",
            "15161/15161 [==============================] - 2s 153us/step - loss: 0.1452 - acc: 0.9433 - f1_m: 0.8919 - precision_m: 0.9182 - recall_m: 0.8832 - val_loss: 0.6437 - val_acc: 0.8053 - val_f1_m: 0.6128 - val_precision_m: 0.6957 - val_recall_m: 0.5698\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00008: early stopping\n",
            "16846/16846 [==============================] - 1s 68us/step\n",
            "cnn Training Loss: 0.2444\n",
            "cnn Training Accuracy: 0.9009\n",
            "cnn Training f1 score: 0.8003\n",
            "cnn Training Precision: 0.9108\n",
            "cnn Training Recall: 0.7307\n",
            "6251/6251 [==============================] - 0s 71us/step\n",
            "cnn Test Loss: 0.3823\n",
            "cnn Test Accuracy: 0.8467\n",
            "cnn Test f1 score: 0.5297\n",
            "cnn Test Precision: 0.6061\n",
            "cnn Test Recall: 0.5091\n",
            "6251/6251 [==============================] - 0s 37us/step\n",
            "6251/6251 [==============================] - 0s 35us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.889     0.927     0.907      5057\n",
            "           1      0.621     0.508     0.559      1194\n",
            "\n",
            "    accuracy                          0.847      6251\n",
            "   macro avg      0.755     0.717     0.733      6251\n",
            "weighted avg      0.837     0.847     0.841      6251\n",
            "\n",
            "cnn  ends..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyN_BDzzw8a6"
      },
      "source": [
        "cnnlstm_test_full_result= pd.DataFrame()\n",
        "cnnlstm_test_full_result['CNN-LSTM-PREDICTON']=list(np.squeeze(prediction_cnnlstm))\n",
        "cnnlstm_test_full_result['CNN-LSTM-PROBS']=probs_cnnlstm\n",
        "cnnlstm_test_full_result['Gold-label']=Y_TEST_ENCODED_FULL\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH4yP7lb3oFM",
        "outputId": "280119a5-ce58-4e81-9dff-84673833e4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "cnnlstm_test_full_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     CNN-LSTM-PREDICTON  CNN-LSTM-PROBS  Gold-label\n",
              "0                     0        0.176501           1\n",
              "1                     0        0.309252           0\n",
              "2                     0        0.260592           0\n",
              "3                     0        0.106699           0\n",
              "4                     0        0.096021           1\n",
              "..                  ...             ...         ...\n",
              "855                   0        0.164990           1\n",
              "856                   0        0.088237           0\n",
              "857                   0        0.392903           1\n",
              "858                   0        0.291047           0\n",
              "859                   0        0.217666           0\n",
              "\n",
              "[860 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-603d1498-408e-4bc4-a9f1-5adec15f1954\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CNN-LSTM-PREDICTON</th>\n",
              "      <th>CNN-LSTM-PROBS</th>\n",
              "      <th>Gold-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.176501</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.309252</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.260592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.106699</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.096021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>0</td>\n",
              "      <td>0.164990</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>0</td>\n",
              "      <td>0.088237</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>0</td>\n",
              "      <td>0.392903</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>0</td>\n",
              "      <td>0.291047</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>0</td>\n",
              "      <td>0.217666</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>860 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-603d1498-408e-4bc4-a9f1-5adec15f1954')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-603d1498-408e-4bc4-a9f1-5adec15f1954 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-603d1498-408e-4bc4-a9f1-5adec15f1954');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHpGJPXbyijg"
      },
      "source": [
        "cnnlstm_test_full_result.to_csv('cnnlstm_test_full_result.csv',header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWwWmH-G4IZi"
      },
      "source": [
        "cnnlstm_valid_full_result= pd.DataFrame()\n",
        "cnnlstm_valid_full_result['CNN-LSTM-PREDICTON']=list(np.squeeze(prediction_cnnlstm))\n",
        "cnnlstm_valid_full_result['CNN-LSTM-PROBS']=probs_cnnlstm\n",
        "cnnlstm_valid_full_result['Gold-label']=Y_TEST_ENCODED_FULL\n",
        "\n",
        "cnnlstm_valid_full_result.to_csv('cnnlstm_valid_full_result.csv',header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIAj4rgXHCP4",
        "outputId": "a37cccb4-462a-4514-ecd9-868ad6ad09a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "cnnlstm_valid_full_result.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    CNN-LSTM-PREDICTON  CNN-LSTM-PROBS  Gold-label\n",
              "0                    0        0.176501           1\n",
              "1                    0        0.309252           0\n",
              "2                    0        0.260592           0\n",
              "3                    0        0.106699           0\n",
              "4                    0        0.096021           1\n",
              "5                    1        0.916323           1\n",
              "6                    0        0.313791           0\n",
              "7                    0        0.115352           1\n",
              "8                    0        0.081312           0\n",
              "9                    0        0.079693           0\n",
              "10                   0        0.249206           0\n",
              "11                   0        0.206582           0\n",
              "12                   0        0.084581           0\n",
              "13                   0        0.038637           0\n",
              "14                   1        0.539551           1\n",
              "15                   1        0.833418           1\n",
              "16                   0        0.318245           0\n",
              "17                   0        0.119607           0\n",
              "18                   0        0.131046           0\n",
              "19                   0        0.356328           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e68ccb92-405f-420b-ad58-80155eb3579f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CNN-LSTM-PREDICTON</th>\n",
              "      <th>CNN-LSTM-PROBS</th>\n",
              "      <th>Gold-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.176501</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.309252</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.260592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.106699</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.096021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0.916323</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0.313791</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0.115352</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0.081312</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0.079693</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0.249206</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0.206582</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0.084581</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0.038637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>0.539551</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>0.833418</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0.318245</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0.119607</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0.131046</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0.356328</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e68ccb92-405f-420b-ad58-80155eb3579f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e68ccb92-405f-420b-ad58-80155eb3579f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e68ccb92-405f-420b-ad58-80155eb3579f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK94JNTgKMtl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
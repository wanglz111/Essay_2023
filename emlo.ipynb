{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elmo\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "url = \"https://tfhub.dev/google/elmo/3\"\n",
    "embed = hub.load(url)\n",
    "\n",
    "from keras.layers import Input, Lambda, Dense,Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.compat.v1.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=X_train['tweet_initial_nontoken'].tolist()\n",
    "trainx = [' '.join(t.split()[0:150]) for t in trainx]\n",
    "trainx = np.array(trainx, dtype=object)[:, np.newaxis]\n",
    "\n",
    "testx = X_test['tweet_initial_nontoken'].tolist()\n",
    "testx = [' '.join(t.split()[0:150]) for t in testx]\n",
    "testx = np.array(testx, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)\n",
    "\n",
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable=True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
    "                               name=\"{}_module\".format(self.name))\n",
    "\n",
    "      #  self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "      #  super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to build model\n",
    "\"\"\"\n",
    "  model.add(Conv1D(128, 3, activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=4))\n",
    "  model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "  model.add(layers.Dense(100, activation='relu'))\n",
    "  model.add(Dense(1, activation='sigmoid'))\"\"\"\n",
    "\n",
    "def build_model(): \n",
    "  input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
    "  embedding = ElmoEmbeddingLayer()(input_text)\n",
    "  #(embedding.shape)\n",
    "  #conv#1 = Conv1D(128, kernel_size=3, activation='relu')(K.expand_dims(embedding,0))\n",
    "  #pool1 = MaxPooling1D(pool_size=4)(conv1)\n",
    "  #conv2 = Conv1D(16, kernel_size=1, activation='relu')(pool1)\n",
    "  #pol2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "  #flat = Flatten()(K.get_shape(pool1,-1,1))\n",
    "  #print(\"a\")\n",
    "  dense = layers.Dense(128, activation='relu')(embedding)\n",
    "\n",
    "  pred = layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "  model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "  #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  model.summary()\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elmo=build_model()\n",
    "early_stopping = [EarlyStopping(monitor='val_acc',min_delta=0,restore_best_weights=True, patience=3,verbose=1, mode='auto')]\n",
    "model_elmo.compile(optimizer=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False),loss='binary_crossentropy',metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "model_elmo.fit(trainx, y_train,\n",
    "            batch_size=16,\n",
    "            epochs=5,\n",
    "            callbacks=early_stopping,\n",
    "            validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model_elmo.evaluate(testx, y_test, verbose=1)\n",
    "print(\"elmo Test Loss: {:.4f}\".format(loss))\n",
    "print(\"elmo Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"elmo Test f1 score: {:.4f}\".format(f1_score))\n",
    "print(\"elmo  Test Precision: {:.4f}\".format(precision))\n",
    "print(\"elmo BiRNN Test Recall: {:.4f}\".format(recall))\n",
    "model_elmo.save('ElmoModel.h5')\n",
    "\n",
    "probs = model_elmo.predict(testx, verbose=1)\n",
    "print('lenght of probs : ' ,len(probs))\n",
    "  #predicted_classes = probs.argmax(axis=-1)\n",
    "predicted_classes=[0 if i < 0.5 else 1 for i in probs]\n",
    "  #predicted_classes = attention_bilstm_model.predict_classes(X_test_initial, verbose=1)\n",
    "  #print(predicted_classes)\n",
    "\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test,predicted_classes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
